{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('Data/user_data.csv', delimiter=';')\n",
    "food_data = pd.read_csv('Data/food_data.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_check = user_data.iloc[:, 20:]\n",
    "count_non_zeros = user_data_check.astype(bool).sum(axis=1)\n",
    "\n",
    "user_data_dup = pd.DataFrame()\n",
    "columns_to_duplicate = user_data.columns[:20]\n",
    "\n",
    "for i, row in user_data.iterrows():\n",
    "    user_data_dup = user_data_dup.append([row[columns_to_duplicate]]*count_non_zeros[i])\n",
    "\n",
    "user_data_dup = user_data_dup.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>643786</th>\n",
       "      <th>157963</th>\n",
       "      <th>638308</th>\n",
       "      <th>660128</th>\n",
       "      <th>638257</th>\n",
       "      <th>647311</th>\n",
       "      <th>638714</th>\n",
       "      <th>652332</th>\n",
       "      <th>652824</th>\n",
       "      <th>654460</th>\n",
       "      <th>...</th>\n",
       "      <th>680975</th>\n",
       "      <th>645863</th>\n",
       "      <th>715448</th>\n",
       "      <th>1697739</th>\n",
       "      <th>636682</th>\n",
       "      <th>653371</th>\n",
       "      <th>660820</th>\n",
       "      <th>634496</th>\n",
       "      <th>634476</th>\n",
       "      <th>649487</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    643786  157963  638308  660128  638257  647311  638714  652332  652824  \\\n",
       "0        3       2       4       1       4       4       4       4       5   \n",
       "1        4       4       4       4       4       4       4       4       4   \n",
       "2        3       3       3       1       3       3       3       2       2   \n",
       "3        5       3       3       4       3       3       4       3       2   \n",
       "4        5       4       4       2       3       4       4       2       5   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "72       5       5       5       5       4       5       5       4       3   \n",
       "73       3       4       4       5       4       5       3       4       4   \n",
       "74       5       5       3       3       5       2       5       2       5   \n",
       "75       5       4       3       1       3       3       4       4       4   \n",
       "76       5       3       4       4       5       4       4       5       4   \n",
       "\n",
       "    654460  ...  680975  645863  715448  1697739  636682  653371  660820  \\\n",
       "0        2  ...       4       5       3        1       1       5       5   \n",
       "1        4  ...       4       4       4        4       4       4       4   \n",
       "2        3  ...       5       4       2        2       2       2       4   \n",
       "3        3  ...       4       3       3        3       3       3       4   \n",
       "4        2  ...       5       4       3        3       5       5       3   \n",
       "..     ...  ...     ...     ...     ...      ...     ...     ...     ...   \n",
       "72       1  ...       1       1       1        1       1       3       5   \n",
       "73       4  ...       3       4       4        4       4       4       4   \n",
       "74       5  ...       5       5       5        5       4       5       5   \n",
       "75       5  ...       3       4       3        3       3       4       4   \n",
       "76       5  ...       5       5       4        5       4       3       4   \n",
       "\n",
       "    634496  634476  649487  \n",
       "0        4       4       5  \n",
       "1        4       4       4  \n",
       "2        2       4       2  \n",
       "3        4       3       4  \n",
       "4        4       4       3  \n",
       "..     ...     ...     ...  \n",
       "72       1       5       3  \n",
       "73       3       4       2  \n",
       "74       5       5       5  \n",
       "75       3       3       3  \n",
       "76       5       4       5  \n",
       "\n",
       "[77 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_data_dup = pd.DataFrame()\n",
    "rating = []\n",
    "\n",
    "for i, row in user_data_check.iterrows():\n",
    "    for j, item in enumerate(row):\n",
    "        if item != 0:\n",
    "            column_name = user_data_check.columns[j]\n",
    "            rating.append(item)\n",
    "            food_row = food_data[food_data['ID'] == int(column_name)]\n",
    "            \n",
    "            if not food_row.empty:\n",
    "                food_data_dup = food_data_dup.append(food_row)\n",
    "\n",
    "food_data_dup = food_data_dup.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Saltiness</th>\n",
       "      <th>Sourness</th>\n",
       "      <th>Bitterness</th>\n",
       "      <th>Savoriness</th>\n",
       "      <th>Fattiness</th>\n",
       "      <th>Spiciness</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Saturated Fat</th>\n",
       "      <th>Carbohydrates</th>\n",
       "      <th>Net Carbohydrates</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Cholestrol</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>643786</td>\n",
       "      <td>Fried Rice - Chinese comfort food</td>\n",
       "      <td>62.74</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>30.79</td>\n",
       "      <td>62.47</td>\n",
       "      <td>98.71</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>422.10</td>\n",
       "      <td>18.88</td>\n",
       "      <td>5.87</td>\n",
       "      <td>46.90</td>\n",
       "      <td>43.58</td>\n",
       "      <td>2.20</td>\n",
       "      <td>144.54</td>\n",
       "      <td>1458.34</td>\n",
       "      <td>15.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157963</td>\n",
       "      <td>Meatball Vegetable Soup</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.43</td>\n",
       "      <td>25.59</td>\n",
       "      <td>36.51</td>\n",
       "      <td>57.44</td>\n",
       "      <td>61.66</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>552.13</td>\n",
       "      <td>17.68</td>\n",
       "      <td>6.37</td>\n",
       "      <td>76.31</td>\n",
       "      <td>70.99</td>\n",
       "      <td>31.84</td>\n",
       "      <td>80.96</td>\n",
       "      <td>850.41</td>\n",
       "      <td>22.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638308</td>\n",
       "      <td>Chicken Satay</td>\n",
       "      <td>15.93</td>\n",
       "      <td>81.12</td>\n",
       "      <td>11.10</td>\n",
       "      <td>14.76</td>\n",
       "      <td>54.83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>833.70</td>\n",
       "      <td>72.88</td>\n",
       "      <td>30.22</td>\n",
       "      <td>19.50</td>\n",
       "      <td>14.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>122.50</td>\n",
       "      <td>1198.05</td>\n",
       "      <td>30.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>660128</td>\n",
       "      <td>Simple Rendang</td>\n",
       "      <td>10.46</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.41</td>\n",
       "      <td>16.59</td>\n",
       "      <td>70.23</td>\n",
       "      <td>56.21</td>\n",
       "      <td>20.25000</td>\n",
       "      <td>727.81</td>\n",
       "      <td>50.25</td>\n",
       "      <td>14.19</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.14</td>\n",
       "      <td>1.48</td>\n",
       "      <td>245.55</td>\n",
       "      <td>327.97</td>\n",
       "      <td>61.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638257</td>\n",
       "      <td>Chicken Porridge</td>\n",
       "      <td>50.03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15.40</td>\n",
       "      <td>26.38</td>\n",
       "      <td>66.94</td>\n",
       "      <td>71.46</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>393.05</td>\n",
       "      <td>6.53</td>\n",
       "      <td>1.58</td>\n",
       "      <td>53.46</td>\n",
       "      <td>51.34</td>\n",
       "      <td>7.27</td>\n",
       "      <td>57.00</td>\n",
       "      <td>826.49</td>\n",
       "      <td>27.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>653371</td>\n",
       "      <td>Nutella Stuffed French Toast</td>\n",
       "      <td>100.00</td>\n",
       "      <td>46.67</td>\n",
       "      <td>8.92</td>\n",
       "      <td>5.14</td>\n",
       "      <td>28.83</td>\n",
       "      <td>68.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>377.81</td>\n",
       "      <td>20.32</td>\n",
       "      <td>15.04</td>\n",
       "      <td>40.27</td>\n",
       "      <td>37.84</td>\n",
       "      <td>35.55</td>\n",
       "      <td>178.09</td>\n",
       "      <td>131.14</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>660820</td>\n",
       "      <td>Spaghetti With Bolognese Sauce</td>\n",
       "      <td>73.05</td>\n",
       "      <td>100.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>42.89</td>\n",
       "      <td>53.62</td>\n",
       "      <td>75.89</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>346.41</td>\n",
       "      <td>27.17</td>\n",
       "      <td>11.04</td>\n",
       "      <td>7.64</td>\n",
       "      <td>5.97</td>\n",
       "      <td>3.74</td>\n",
       "      <td>76.09</td>\n",
       "      <td>749.20</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>634496</td>\n",
       "      <td>BBQ Mac and Cheese</td>\n",
       "      <td>100.00</td>\n",
       "      <td>80.72</td>\n",
       "      <td>48.67</td>\n",
       "      <td>40.53</td>\n",
       "      <td>89.21</td>\n",
       "      <td>95.09</td>\n",
       "      <td>0.03675</td>\n",
       "      <td>812.67</td>\n",
       "      <td>25.59</td>\n",
       "      <td>13.88</td>\n",
       "      <td>109.20</td>\n",
       "      <td>104.26</td>\n",
       "      <td>17.21</td>\n",
       "      <td>70.09</td>\n",
       "      <td>1250.65</td>\n",
       "      <td>36.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>634476</td>\n",
       "      <td>Bbq Chicken</td>\n",
       "      <td>21.30</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.34</td>\n",
       "      <td>16.50</td>\n",
       "      <td>69.85</td>\n",
       "      <td>55.59</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>478.31</td>\n",
       "      <td>29.24</td>\n",
       "      <td>8.32</td>\n",
       "      <td>15.21</td>\n",
       "      <td>15.03</td>\n",
       "      <td>12.96</td>\n",
       "      <td>144.58</td>\n",
       "      <td>886.82</td>\n",
       "      <td>37.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>649487</td>\n",
       "      <td>Lemon - Garlic Chicken</td>\n",
       "      <td>11.95</td>\n",
       "      <td>100.00</td>\n",
       "      <td>57.37</td>\n",
       "      <td>47.64</td>\n",
       "      <td>71.64</td>\n",
       "      <td>67.72</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>797.61</td>\n",
       "      <td>40.06</td>\n",
       "      <td>6.49</td>\n",
       "      <td>10.16</td>\n",
       "      <td>9.33</td>\n",
       "      <td>3.10</td>\n",
       "      <td>289.28</td>\n",
       "      <td>721.95</td>\n",
       "      <td>96.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3439 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                               Name  Sweetness  Saltiness  \\\n",
       "0     643786  Fried Rice - Chinese comfort food      62.74     100.00   \n",
       "1     157963            Meatball Vegetable Soup     100.00      99.43   \n",
       "2     638308                      Chicken Satay      15.93      81.12   \n",
       "3     660128                     Simple Rendang      10.46     100.00   \n",
       "4     638257                   Chicken Porridge      50.03     100.00   \n",
       "...      ...                                ...        ...        ...   \n",
       "3434  653371       Nutella Stuffed French Toast     100.00      46.67   \n",
       "3435  660820     Spaghetti With Bolognese Sauce      73.05     100.00   \n",
       "3436  634496                 BBQ Mac and Cheese     100.00      80.72   \n",
       "3437  634476                        Bbq Chicken      21.30     100.00   \n",
       "3438  649487             Lemon - Garlic Chicken      11.95     100.00   \n",
       "\n",
       "      Sourness  Bitterness  Savoriness  Fattiness  Spiciness  Calories    Fat  \\\n",
       "0        18.40       30.79       62.47      98.71    0.00000    422.10  18.88   \n",
       "1        25.59       36.51       57.44      61.66    0.00000    552.13  17.68   \n",
       "2        11.10       14.76       54.83     100.00    0.00000    833.70  72.88   \n",
       "3        13.41       16.59       70.23      56.21   20.25000    727.81  50.25   \n",
       "4        15.40       26.38       66.94      71.46    0.00000    393.05   6.53   \n",
       "...        ...         ...         ...        ...        ...       ...    ...   \n",
       "3434      8.92        5.14       28.83      68.25    0.00000    377.81  20.32   \n",
       "3435     62.00       42.89       53.62      75.89    0.00000    346.41  27.17   \n",
       "3436     48.67       40.53       89.21      95.09    0.03675    812.67  25.59   \n",
       "3437     13.34       16.50       69.85      55.59    0.00000    478.31  29.24   \n",
       "3438     57.37       47.64       71.64      67.72    0.00000    797.61  40.06   \n",
       "\n",
       "      Saturated Fat  Carbohydrates  Net Carbohydrates  Sugar  Cholestrol  \\\n",
       "0              5.87          46.90              43.58   2.20      144.54   \n",
       "1              6.37          76.31              70.99  31.84       80.96   \n",
       "2             30.22          19.50              14.80   7.41      122.50   \n",
       "3             14.19           4.53               4.14   1.48      245.55   \n",
       "4              1.58          53.46              51.34   7.27       57.00   \n",
       "...             ...            ...                ...    ...         ...   \n",
       "3434          15.04          40.27              37.84  35.55      178.09   \n",
       "3435          11.04           7.64               5.97   3.74       76.09   \n",
       "3436          13.88         109.20             104.26  17.21       70.09   \n",
       "3437           8.32          15.21              15.03  12.96      144.58   \n",
       "3438           6.49          10.16               9.33   3.10      289.28   \n",
       "\n",
       "       Sodium  Protein  \n",
       "0     1458.34    15.75  \n",
       "1      850.41    22.41  \n",
       "2     1198.05    30.81  \n",
       "3      327.97    61.30  \n",
       "4      826.49    27.74  \n",
       "...       ...      ...  \n",
       "3434   131.14     8.83  \n",
       "3435   749.20     2.12  \n",
       "3436  1250.65    36.22  \n",
       "3437   886.82    37.10  \n",
       "3438   721.95    96.76  \n",
       "\n",
       "[3439 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_data = user_data_dup.drop(columns=['ID', 'Nama', 'Calories', 'Protein', 'Fat', 'Carbohydrates'])\n",
    "train_food_data = food_data_dup.drop(columns=['ID', 'Name', 'Type', 'Link', 'Image_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_data = pd.get_dummies(train_user_data, prefix=['Gender', 'Activity_Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Fruit</th>\n",
       "      <th>Healthy</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Saltiness</th>\n",
       "      <th>Sourness</th>\n",
       "      <th>Bitterness</th>\n",
       "      <th>Savoriness</th>\n",
       "      <th>Fattiness</th>\n",
       "      <th>Spiciness</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Active_Active</th>\n",
       "      <th>Active_Light activity</th>\n",
       "      <th>Active_Moderate active</th>\n",
       "      <th>Active_Not active</th>\n",
       "      <th>Active_Very active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.716420</td>\n",
       "      <td>3.032389</td>\n",
       "      <td>1.057807</td>\n",
       "      <td>0.939549</td>\n",
       "      <td>2.007276</td>\n",
       "      <td>2.654416</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.716420</td>\n",
       "      <td>3.032389</td>\n",
       "      <td>1.057807</td>\n",
       "      <td>0.939549</td>\n",
       "      <td>2.007276</td>\n",
       "      <td>2.654416</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.716420</td>\n",
       "      <td>3.032389</td>\n",
       "      <td>1.057807</td>\n",
       "      <td>0.939549</td>\n",
       "      <td>2.007276</td>\n",
       "      <td>2.654416</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.716420</td>\n",
       "      <td>3.032389</td>\n",
       "      <td>1.057807</td>\n",
       "      <td>0.939549</td>\n",
       "      <td>2.007276</td>\n",
       "      <td>2.654416</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.716420</td>\n",
       "      <td>3.032389</td>\n",
       "      <td>1.057807</td>\n",
       "      <td>0.939549</td>\n",
       "      <td>2.007276</td>\n",
       "      <td>2.654416</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.997396</td>\n",
       "      <td>3.682549</td>\n",
       "      <td>1.324011</td>\n",
       "      <td>1.223742</td>\n",
       "      <td>2.435298</td>\n",
       "      <td>3.151791</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.997396</td>\n",
       "      <td>3.682549</td>\n",
       "      <td>1.324011</td>\n",
       "      <td>1.223742</td>\n",
       "      <td>2.435298</td>\n",
       "      <td>3.151791</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.997396</td>\n",
       "      <td>3.682549</td>\n",
       "      <td>1.324011</td>\n",
       "      <td>1.223742</td>\n",
       "      <td>2.435298</td>\n",
       "      <td>3.151791</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.997396</td>\n",
       "      <td>3.682549</td>\n",
       "      <td>1.324011</td>\n",
       "      <td>1.223742</td>\n",
       "      <td>2.435298</td>\n",
       "      <td>3.151791</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.997396</td>\n",
       "      <td>3.682549</td>\n",
       "      <td>1.324011</td>\n",
       "      <td>1.223742</td>\n",
       "      <td>2.435298</td>\n",
       "      <td>3.151791</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3439 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Height  Weight  Fruit  Healthy  Sweetness  Saltiness  Sourness  \\\n",
       "0      25     165      44      2        2   1.716420   3.032389  1.057807   \n",
       "1      25     165      44      2        2   1.716420   3.032389  1.057807   \n",
       "2      25     165      44      2        2   1.716420   3.032389  1.057807   \n",
       "3      25     165      44      2        2   1.716420   3.032389  1.057807   \n",
       "4      25     165      44      2        2   1.716420   3.032389  1.057807   \n",
       "...   ...     ...     ...    ...      ...        ...        ...       ...   \n",
       "3434   20     168      70      4        4   1.997396   3.682549  1.324011   \n",
       "3435   20     168      70      4        4   1.997396   3.682549  1.324011   \n",
       "3436   20     168      70      4        4   1.997396   3.682549  1.324011   \n",
       "3437   20     168      70      4        4   1.997396   3.682549  1.324011   \n",
       "3438   20     168      70      4        4   1.997396   3.682549  1.324011   \n",
       "\n",
       "      Bitterness  Savoriness  Fattiness  Spiciness  Gender_Female  \\\n",
       "0       0.939549    2.007276   2.654416   0.011805              1   \n",
       "1       0.939549    2.007276   2.654416   0.011805              1   \n",
       "2       0.939549    2.007276   2.654416   0.011805              1   \n",
       "3       0.939549    2.007276   2.654416   0.011805              1   \n",
       "4       0.939549    2.007276   2.654416   0.011805              1   \n",
       "...          ...         ...        ...        ...            ...   \n",
       "3434    1.223742    2.435298   3.151791   0.032304              0   \n",
       "3435    1.223742    2.435298   3.151791   0.032304              0   \n",
       "3436    1.223742    2.435298   3.151791   0.032304              0   \n",
       "3437    1.223742    2.435298   3.151791   0.032304              0   \n",
       "3438    1.223742    2.435298   3.151791   0.032304              0   \n",
       "\n",
       "      Gender_Male  Active_Active  Active_Light activity  \\\n",
       "0               0              1                      0   \n",
       "1               0              1                      0   \n",
       "2               0              1                      0   \n",
       "3               0              1                      0   \n",
       "4               0              1                      0   \n",
       "...           ...            ...                    ...   \n",
       "3434            1              1                      0   \n",
       "3435            1              1                      0   \n",
       "3436            1              1                      0   \n",
       "3437            1              1                      0   \n",
       "3438            1              1                      0   \n",
       "\n",
       "      Active_Moderate active  Active_Not active  Active_Very active  \n",
       "0                          0                  0                   0  \n",
       "1                          0                  0                   0  \n",
       "2                          0                  0                   0  \n",
       "3                          0                  0                   0  \n",
       "4                          0                  0                   0  \n",
       "...                      ...                ...                 ...  \n",
       "3434                       0                  0                   0  \n",
       "3435                       0                  0                   0  \n",
       "3436                       0                  0                   0  \n",
       "3437                       0                  0                   0  \n",
       "3438                       0                  0                   0  \n",
       "\n",
       "[3439 rows x 19 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Saltiness</th>\n",
       "      <th>Sourness</th>\n",
       "      <th>Bitterness</th>\n",
       "      <th>Savoriness</th>\n",
       "      <th>Fattiness</th>\n",
       "      <th>Spiciness</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Saturated Fat</th>\n",
       "      <th>Carbohydrates</th>\n",
       "      <th>Net Carbohydrates</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Cholestrol</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.74</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>30.79</td>\n",
       "      <td>62.47</td>\n",
       "      <td>98.71</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>422.10</td>\n",
       "      <td>18.88</td>\n",
       "      <td>5.87</td>\n",
       "      <td>46.90</td>\n",
       "      <td>43.58</td>\n",
       "      <td>2.20</td>\n",
       "      <td>144.54</td>\n",
       "      <td>1458.34</td>\n",
       "      <td>15.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.00</td>\n",
       "      <td>99.43</td>\n",
       "      <td>25.59</td>\n",
       "      <td>36.51</td>\n",
       "      <td>57.44</td>\n",
       "      <td>61.66</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>552.13</td>\n",
       "      <td>17.68</td>\n",
       "      <td>6.37</td>\n",
       "      <td>76.31</td>\n",
       "      <td>70.99</td>\n",
       "      <td>31.84</td>\n",
       "      <td>80.96</td>\n",
       "      <td>850.41</td>\n",
       "      <td>22.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.93</td>\n",
       "      <td>81.12</td>\n",
       "      <td>11.10</td>\n",
       "      <td>14.76</td>\n",
       "      <td>54.83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>833.70</td>\n",
       "      <td>72.88</td>\n",
       "      <td>30.22</td>\n",
       "      <td>19.50</td>\n",
       "      <td>14.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>122.50</td>\n",
       "      <td>1198.05</td>\n",
       "      <td>30.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.46</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.41</td>\n",
       "      <td>16.59</td>\n",
       "      <td>70.23</td>\n",
       "      <td>56.21</td>\n",
       "      <td>20.25000</td>\n",
       "      <td>727.81</td>\n",
       "      <td>50.25</td>\n",
       "      <td>14.19</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.14</td>\n",
       "      <td>1.48</td>\n",
       "      <td>245.55</td>\n",
       "      <td>327.97</td>\n",
       "      <td>61.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15.40</td>\n",
       "      <td>26.38</td>\n",
       "      <td>66.94</td>\n",
       "      <td>71.46</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>393.05</td>\n",
       "      <td>6.53</td>\n",
       "      <td>1.58</td>\n",
       "      <td>53.46</td>\n",
       "      <td>51.34</td>\n",
       "      <td>7.27</td>\n",
       "      <td>57.00</td>\n",
       "      <td>826.49</td>\n",
       "      <td>27.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>100.00</td>\n",
       "      <td>46.67</td>\n",
       "      <td>8.92</td>\n",
       "      <td>5.14</td>\n",
       "      <td>28.83</td>\n",
       "      <td>68.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>377.81</td>\n",
       "      <td>20.32</td>\n",
       "      <td>15.04</td>\n",
       "      <td>40.27</td>\n",
       "      <td>37.84</td>\n",
       "      <td>35.55</td>\n",
       "      <td>178.09</td>\n",
       "      <td>131.14</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>73.05</td>\n",
       "      <td>100.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>42.89</td>\n",
       "      <td>53.62</td>\n",
       "      <td>75.89</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>346.41</td>\n",
       "      <td>27.17</td>\n",
       "      <td>11.04</td>\n",
       "      <td>7.64</td>\n",
       "      <td>5.97</td>\n",
       "      <td>3.74</td>\n",
       "      <td>76.09</td>\n",
       "      <td>749.20</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>100.00</td>\n",
       "      <td>80.72</td>\n",
       "      <td>48.67</td>\n",
       "      <td>40.53</td>\n",
       "      <td>89.21</td>\n",
       "      <td>95.09</td>\n",
       "      <td>0.03675</td>\n",
       "      <td>812.67</td>\n",
       "      <td>25.59</td>\n",
       "      <td>13.88</td>\n",
       "      <td>109.20</td>\n",
       "      <td>104.26</td>\n",
       "      <td>17.21</td>\n",
       "      <td>70.09</td>\n",
       "      <td>1250.65</td>\n",
       "      <td>36.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>21.30</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.34</td>\n",
       "      <td>16.50</td>\n",
       "      <td>69.85</td>\n",
       "      <td>55.59</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>478.31</td>\n",
       "      <td>29.24</td>\n",
       "      <td>8.32</td>\n",
       "      <td>15.21</td>\n",
       "      <td>15.03</td>\n",
       "      <td>12.96</td>\n",
       "      <td>144.58</td>\n",
       "      <td>886.82</td>\n",
       "      <td>37.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>11.95</td>\n",
       "      <td>100.00</td>\n",
       "      <td>57.37</td>\n",
       "      <td>47.64</td>\n",
       "      <td>71.64</td>\n",
       "      <td>67.72</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>797.61</td>\n",
       "      <td>40.06</td>\n",
       "      <td>6.49</td>\n",
       "      <td>10.16</td>\n",
       "      <td>9.33</td>\n",
       "      <td>3.10</td>\n",
       "      <td>289.28</td>\n",
       "      <td>721.95</td>\n",
       "      <td>96.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3439 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sweetness  Saltiness  Sourness  Bitterness  Savoriness  Fattiness  \\\n",
       "0         62.74     100.00     18.40       30.79       62.47      98.71   \n",
       "1        100.00      99.43     25.59       36.51       57.44      61.66   \n",
       "2         15.93      81.12     11.10       14.76       54.83     100.00   \n",
       "3         10.46     100.00     13.41       16.59       70.23      56.21   \n",
       "4         50.03     100.00     15.40       26.38       66.94      71.46   \n",
       "...         ...        ...       ...         ...         ...        ...   \n",
       "3434     100.00      46.67      8.92        5.14       28.83      68.25   \n",
       "3435      73.05     100.00     62.00       42.89       53.62      75.89   \n",
       "3436     100.00      80.72     48.67       40.53       89.21      95.09   \n",
       "3437      21.30     100.00     13.34       16.50       69.85      55.59   \n",
       "3438      11.95     100.00     57.37       47.64       71.64      67.72   \n",
       "\n",
       "      Spiciness  Calories    Fat  Saturated Fat  Carbohydrates  \\\n",
       "0       0.00000    422.10  18.88           5.87          46.90   \n",
       "1       0.00000    552.13  17.68           6.37          76.31   \n",
       "2       0.00000    833.70  72.88          30.22          19.50   \n",
       "3      20.25000    727.81  50.25          14.19           4.53   \n",
       "4       0.00000    393.05   6.53           1.58          53.46   \n",
       "...         ...       ...    ...            ...            ...   \n",
       "3434    0.00000    377.81  20.32          15.04          40.27   \n",
       "3435    0.00000    346.41  27.17          11.04           7.64   \n",
       "3436    0.03675    812.67  25.59          13.88         109.20   \n",
       "3437    0.00000    478.31  29.24           8.32          15.21   \n",
       "3438    0.00000    797.61  40.06           6.49          10.16   \n",
       "\n",
       "      Net Carbohydrates  Sugar  Cholestrol   Sodium  Protein  \n",
       "0                 43.58   2.20      144.54  1458.34    15.75  \n",
       "1                 70.99  31.84       80.96   850.41    22.41  \n",
       "2                 14.80   7.41      122.50  1198.05    30.81  \n",
       "3                  4.14   1.48      245.55   327.97    61.30  \n",
       "4                 51.34   7.27       57.00   826.49    27.74  \n",
       "...                 ...    ...         ...      ...      ...  \n",
       "3434              37.84  35.55      178.09   131.14     8.83  \n",
       "3435               5.97   3.74       76.09   749.20     2.12  \n",
       "3436             104.26  17.21       70.09  1250.65    36.22  \n",
       "3437              15.03  12.96      144.58   886.82    37.10  \n",
       "3438               9.33   3.10      289.28   721.95    96.76  \n",
       "\n",
       "[3439 rows x 16 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_food_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "item_train_unscaled = train_food_data\n",
    "user_train_unscaled = train_user_data\n",
    "rating = np.array(rating)\n",
    "y_train_unscaled    = rating\n",
    "\n",
    "scalerItem = StandardScaler()\n",
    "scalerItem.fit(train_food_data)\n",
    "item_train = scalerItem.transform(train_food_data)\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "scalerUser.fit(train_user_data)\n",
    "user_train = scalerUser.transform(train_user_data)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))\n",
    "scalerTarget.fit(rating.reshape(-1, 1))\n",
    "y_train = scalerTarget.transform(rating.reshape(-1, 1))\n",
    "\n",
    "print(np.allclose(item_train_unscaled, scalerItem.inverse_transform(item_train)))\n",
    "print(np.allclose(user_train_unscaled, scalerUser.inverse_transform(user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 19)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 32)           178592      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 32)           47584       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOpLamb  (None, 32)          0           ['sequential[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_1 (TFOpLa  (None, 32)          0           ['sequential_1[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['tf.math.l2_normalize[0][0]',   \n",
      "                                                                  'tf.math.l2_normalize_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 226,176\n",
      "Trainable params: 226,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=num_outputs)\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=num_outputs)\n",
    "])\n",
    "\n",
    "input_user = tf.keras.layers.Input(shape=(19))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "input_item = tf.keras.layers.Input(shape=(16))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "86/86 [==============================] - 5s 7ms/step - loss: 0.2666\n",
      "Epoch 2/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.2352\n",
      "Epoch 3/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.2250\n",
      "Epoch 4/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.2167\n",
      "Epoch 5/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.2094\n",
      "Epoch 6/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.2034\n",
      "Epoch 7/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1963\n",
      "Epoch 8/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1909\n",
      "Epoch 9/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1863\n",
      "Epoch 10/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1821\n",
      "Epoch 11/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1783\n",
      "Epoch 12/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1749\n",
      "Epoch 13/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1726\n",
      "Epoch 14/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1703\n",
      "Epoch 15/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1682\n",
      "Epoch 16/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1656\n",
      "Epoch 17/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1646\n",
      "Epoch 18/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1619\n",
      "Epoch 19/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1608\n",
      "Epoch 20/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1595\n",
      "Epoch 21/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1578\n",
      "Epoch 22/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1566\n",
      "Epoch 23/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1560\n",
      "Epoch 24/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1558\n",
      "Epoch 25/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1543\n",
      "Epoch 26/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1526\n",
      "Epoch 27/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1525\n",
      "Epoch 28/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1517\n",
      "Epoch 29/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1516\n",
      "Epoch 30/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1507\n",
      "Epoch 31/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1502\n",
      "Epoch 32/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1508\n",
      "Epoch 33/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1495\n",
      "Epoch 34/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1487\n",
      "Epoch 35/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1487\n",
      "Epoch 36/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1480\n",
      "Epoch 37/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1481\n",
      "Epoch 38/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1479\n",
      "Epoch 39/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1472\n",
      "Epoch 40/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1469\n",
      "Epoch 41/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1469\n",
      "Epoch 42/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1455\n",
      "Epoch 43/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1463\n",
      "Epoch 44/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1451\n",
      "Epoch 45/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1455\n",
      "Epoch 46/50\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.1455\n",
      "Epoch 47/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1448\n",
      "Epoch 48/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1447\n",
      "Epoch 49/50\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.1448\n",
      "Epoch 50/50\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.1441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3b0204b88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([user_train, item_train], y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.0516453]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict for index 1 test data\n",
    "x = model.predict([user_test[34].reshape(1, 19), item_test[34].reshape(1, 16)])\n",
    "#inverse transform the prediction\n",
    "x = scalerTarget.inverse_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.375146]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = scalerTarget.inverse_transform(y_test[34].reshape(1, 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('recommendation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('scalerUser.pkl', 'wb') as f:\n",
    "    pickle.dump(scalerUser, f)\n",
    "\n",
    "with open('scalerItem.pkl', 'wb') as f:\n",
    "    pickle.dump(scalerItem, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.40000000e+01, 1.73000000e+02, 6.80000000e+01, 5.00000000e+00,\n",
       "       4.00000000e+00, 1.68352000e+00, 3.10404444e+00, 1.14139778e+00,\n",
       "       9.92208889e-01, 2.08114889e+00, 2.68727778e+00, 2.24645420e-02,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalerUser.inverse_transform(user_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bangkit\\.conda\\envs\\tf210\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Users\\Bangkit\\.conda\\envs\\tf210\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "user_new = np.array([25,165,44,2,2,1.716420,3.032389,1.057807,0.939549,2.007276,2.654416,0.011805,1,0,1,0,0,0,0]).reshape(1, 19)\n",
    "item_new = np.array([10.46,100,13.41,16.59,70.23,56.21,20.25,727.81,50.25,14.19,4.53,4.14,1.48,245.55,327.97,61.3]).reshape(1, 16)\n",
    "\n",
    "user_new = scalerUser.transform(user_new)\n",
    "item_new = scalerItem.transform(item_new)\n",
    "\n",
    "rate = model.predict([user_new, item_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = scalerTarget.inverse_transform(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4508297]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
